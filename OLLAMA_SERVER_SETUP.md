# ðŸš€ GuÃ­a Completa: Servidor Ollama Propio

## ðŸ“‹ Tabla de Contenidos
1. [Requisitos](#requisitos)
2. [Opciones de Hosting](#opciones-de-hosting)
3. [InstalaciÃ³n Automatizada](#instalaciÃ³n-automatizada)
4. [ConfiguraciÃ³n DNS](#configuraciÃ³n-dns)
5. [ConfiguraciÃ³n en Vercel](#configuraciÃ³n-en-vercel)
6. [VerificaciÃ³n y Testing](#verificaciÃ³n-y-testing)
7. [Mantenimiento](#mantenimiento)
8. [Troubleshooting](#troubleshooting)

---

## ðŸŽ¯ Requisitos

### Servidor (VPS/Cloud)
- **CPU**: MÃ­nimo 4 cores (8+ recomendado)
- **RAM**: MÃ­nimo 16GB (32GB+ recomendado para modelos grandes)
- **Disco**: 100GB+ SSD (modelos ocupan 20-40GB cada uno)
- **OS**: Ubuntu 20.04+, Debian 11+, o cualquier Linux compatible
- **Ancho de banda**: Ilimitado (opcional pero recomendado)

### Dominio
- Un dominio o subdominio (ej: `ollama.tu-empresa.com`)
- Acceso a configuraciÃ³n DNS

### Conocimientos
- BÃ¡sicos de SSH
- ConfiguraciÃ³n bÃ¡sica de servidores Linux

---

## ðŸ’° Opciones de Hosting

### 1ï¸âƒ£ **DigitalOcean** (Recomendado para principiantes)
```
ðŸ’µ Costo: $48/mes
ðŸ“Š Specs: 8 GB RAM, 4 vCPUs, 160 GB SSD
ðŸŒ UbicaciÃ³n: MÃºltiples regiones
âœ… FÃ¡cil de usar, panel intuitivo
```

**Pasos:**
1. Crear cuenta en [DigitalOcean](https://www.digitalocean.com)
2. Crear Droplet â†’ Ubuntu 22.04 LTS
3. Elegir plan: **Basic** (8GB RAM / 4 vCPUs) - $48/mes
4. Seleccionar regiÃ³n cercana a tus usuarios
5. AÃ±adir SSH key
6. Crear Droplet

### 2ï¸âƒ£ **Hetzner Cloud** (Mejor precio/performance)
```
ðŸ’µ Costo: â‚¬15.90/mes (~$17/mes)
ðŸ“Š Specs: 16 GB RAM, 4 vCPUs, 160 GB SSD
ðŸŒ UbicaciÃ³n: Europa, USA
âœ… Excelente relaciÃ³n calidad-precio
```

**Pasos:**
1. Crear cuenta en [Hetzner](https://www.hetzner.com/cloud)
2. Crear servidor â†’ CPX31 (16GB RAM)
3. Seleccionar Ubuntu 22.04
4. Configurar SSH key
5. Crear servidor

### 3ï¸âƒ£ **Vultr** (Balance precio/ubicaciones)
```
ðŸ’µ Costo: $48/mes
ðŸ“Š Specs: 16 GB RAM, 4 vCPUs, 320 GB SSD
ðŸŒ UbicaciÃ³n: 25+ ubicaciones globales
âœ… Buena cobertura global
```

### 4ï¸âƒ£ **AWS EC2** (Empresarial)
```
ðŸ’µ Costo: ~$70-100/mes
ðŸ“Š Specs: t3.xlarge (16GB RAM, 4 vCPUs)
ðŸŒ UbicaciÃ³n: Global
âœ… MÃ¡xima escalabilidad
```

### 5ï¸âƒ£ **Google Cloud** (CrÃ©ditos gratis)
```
ðŸ’µ Costo: $300 crÃ©ditos gratis primer aÃ±o
ðŸ“Š Specs: Customizable
ðŸŒ UbicaciÃ³n: Global
âœ… Bueno para empezar gratis
```

---

## ðŸš€ InstalaciÃ³n Automatizada

### Paso 1: Conectar por SSH

```bash
# Conectar a tu servidor
ssh root@TU_IP_DEL_SERVIDOR

# Si usas SSH key:
ssh -i ~/.ssh/id_rsa root@TU_IP_DEL_SERVIDOR
```

### Paso 2: Descargar y ejecutar script

```bash
# Descargar script de instalaciÃ³n
wget https://raw.githubusercontent.com/TU_USUARIO/premium-ecosystem/main/setup-ollama-server.sh

# O si no tienes el repo pÃºblico, copia manualmente el contenido a:
nano setup-ollama-server.sh
# Pega el contenido del script y guarda (Ctrl+X, Y, Enter)

# Dar permisos de ejecuciÃ³n
chmod +x setup-ollama-server.sh

# Ejecutar (tomarÃ¡ 15-30 minutos)
sudo bash setup-ollama-server.sh
```

### Paso 3: Ingresar informaciÃ³n cuando se solicite

El script te pedirÃ¡:
- **Dominio**: `ollama.tu-empresa.com`
- **Email**: `tu@email.com` (para certificados SSL)

### âœ… Script instala automÃ¡ticamente:
- âœ… Ollama v0.12+
- âœ… Nginx como proxy inverso
- âœ… Certificado SSL con Let's Encrypt
- âœ… Firewall configurado (UFW)
- âœ… 4 modelos principales:
  - `qwen2.5:32b` (mejor para espaÃ±ol)
  - `llama3.2` (rÃ¡pido)
  - `codellama` (cÃ³digo)
  - `mistral` (balance)
- âœ… CORS habilitado
- âœ… Rate limiting
- âœ… Script de monitoreo

---

## ðŸŒ ConfiguraciÃ³n DNS

### OpciÃ³n A: Cloudflare (Recomendado)

1. **AÃ±adir dominio a Cloudflare** (si no lo tienes ya)
2. **Crear registro A**:
   ```
   Tipo: A
   Nombre: ollama
   Contenido: IP_DE_TU_SERVIDOR
   Proxy: âŒ Desactivado (solo DNS)
   TTL: AutomÃ¡tico
   ```

3. **Esperar propagaciÃ³n** (1-5 minutos)

4. **Verificar**:
   ```bash
   # Desde tu PC local
   ping ollama.tu-empresa.com
   # Debe responder con la IP de tu servidor
   ```

### OpciÃ³n B: Cualquier proveedor DNS

AÃ±ade un registro A:
- **Host**: `ollama`
- **Tipo**: `A`
- **Valor**: `IP_DE_TU_SERVIDOR`
- **TTL**: `300` (5 minutos)

---

## âš™ï¸ ConfiguraciÃ³n en Vercel

### OpciÃ³n 1: Dashboard de Vercel (FÃ¡cil)

1. **Ir a tu proyecto en Vercel**: https://vercel.com/dashboard
2. **Settings** â†’ **Environment Variables**
3. **AÃ±adir nueva variable**:
   ```
   Name: VITE_OLLAMA_HOST
   Value: https://ollama.tu-empresa.com
   Environment: Production
   ```
4. **Save**

### OpciÃ³n 2: Vercel CLI (RÃ¡pido)

```bash
# Desde tu proyecto local
vercel env add VITE_OLLAMA_HOST

# Cuando pregunte:
# Value: https://ollama.tu-empresa.com
# Add to which environment? Production
```

### OpciÃ³n 3: Archivo `.env.production`

```bash
# Crear archivo .env.production en la raÃ­z
cat > .env.production << EOF
VITE_OLLAMA_HOST=https://ollama.tu-empresa.com
EOF

# El archivo se ignorarÃ¡ en .gitignore (seguridad)
# Pero Vercel lo leerÃ¡ automÃ¡ticamente
```

---

## ðŸ§ª VerificaciÃ³n y Testing

### 1. Verificar servidor Ollama

```bash
# Desde tu servidor VPS (SSH)
sudo systemctl status ollama

# DeberÃ­a mostrar: active (running)
```

### 2. Test de API local

```bash
# En el servidor
curl http://localhost:11434/api/tags

# Debe retornar JSON con lista de modelos
```

### 3. Test de API pÃºblica (HTTPS)

```bash
# Desde tu PC local
curl https://ollama.tu-empresa.com/api/tags

# Debe retornar JSON con modelos
```

### 4. Test de generaciÃ³n

```bash
# Test completo de chat
curl https://ollama.tu-empresa.com/api/generate -d '{
  "model": "qwen2.5:32b",
  "prompt": "Hola, Â¿cÃ³mo estÃ¡s?",
  "stream": false
}'

# Debe retornar respuesta del modelo
```

### 5. Verificar desde tu app

1. **Deployer nueva versiÃ³n** a Vercel:
   ```bash
   npm run build
   vercel --prod --yes
   ```

2. **Abrir tu app** en producciÃ³n

3. **Abrir el AI Assistant** (botÃ³n ðŸ§ )

4. **Enviar mensaje de prueba**

5. **Verificar respuesta** del servidor remoto

---

## ðŸ”§ Mantenimiento

### Comandos Ãºtiles del servidor

```bash
# Ver logs en tiempo real
journalctl -u ollama -f

# Reiniciar Ollama
sudo systemctl restart ollama

# Ver estado
sudo systemctl status ollama

# Script de monitoreo
ollama-monitor.sh

# Listar modelos instalados
sudo -u ollama ollama list

# Descargar mÃ¡s modelos
sudo -u ollama ollama pull nombre-modelo

# Ver uso de recursos
htop
```

### RenovaciÃ³n SSL (automÃ¡tica)

Certbot renueva automÃ¡ticamente cada 60 dÃ­as. Verificar:

```bash
# Ver certificados
sudo certbot certificates

# Test de renovaciÃ³n (no renueva realmente)
sudo certbot renew --dry-run
```

### Actualizar Ollama

```bash
# Detener servicio
sudo systemctl stop ollama

# Actualizar
curl -fsSL https://ollama.com/install.sh | sh

# Reiniciar
sudo systemctl start ollama

# Verificar versiÃ³n
ollama --version
```

### Backup de modelos

```bash
# Los modelos estÃ¡n en:
/usr/share/ollama/.ollama/models/

# Backup
sudo tar -czf ollama-models-backup.tar.gz /usr/share/ollama/.ollama/models/

# Restaurar
sudo tar -xzf ollama-models-backup.tar.gz -C /
```

---

## ðŸ› Troubleshooting

### Problema: "No se puede conectar con Ollama"

**SoluciÃ³n 1**: Verificar que el servicio estÃ© corriendo
```bash
sudo systemctl status ollama
# Si no estÃ¡ activo:
sudo systemctl start ollama
```

**SoluciÃ³n 2**: Verificar Nginx
```bash
sudo systemctl status nginx
sudo nginx -t  # Verificar configuraciÃ³n
sudo systemctl restart nginx
```

**SoluciÃ³n 3**: Verificar firewall
```bash
sudo ufw status
# Debe mostrar:
# 80/tcp    ALLOW
# 443/tcp   ALLOW
```

### Problema: "SSL certificate error"

**SoluciÃ³n**: Renovar certificado
```bash
sudo certbot renew --force-renewal
sudo systemctl restart nginx
```

### Problema: "Modelo no responde / muy lento"

**SoluciÃ³n 1**: Verificar RAM disponible
```bash
free -h
# Si estÃ¡ lleno, reiniciar Ollama
sudo systemctl restart ollama
```

**SoluciÃ³n 2**: Usar modelo mÃ¡s pequeÃ±o
```bash
# Cambiar en tu app de qwen2.5:32b a llama3.2
# O desde servidor:
sudo -u ollama ollama pull llama3.2
```

### Problema: "Rate limit exceeded"

**SoluciÃ³n**: Ajustar rate limit en Nginx
```bash
sudo nano /etc/nginx/conf.d/rate-limit.conf

# Cambiar: rate=10r/s por rate=20r/s
# Guardar y reiniciar:
sudo systemctl restart nginx
```

### Problema: "CORS error en producciÃ³n"

**SoluciÃ³n**: Verificar headers CORS en Nginx
```bash
sudo nano /etc/nginx/sites-available/ollama

# Asegurar que tenga:
# add_header 'Access-Control-Allow-Origin' '*' always;

sudo nginx -t
sudo systemctl restart nginx
```

### Problema: "502 Bad Gateway"

**SoluciÃ³n**: Ollama no estÃ¡ respondiendo
```bash
# Ver logs
journalctl -u ollama -n 50

# Reiniciar todo
sudo systemctl restart ollama
sleep 5
sudo systemctl restart nginx
```

---

## ðŸ“Š Monitoreo de Costos

### Estimaciones mensuales

| Proveedor | Plan | Costo/mes | Modelos soportados |
|-----------|------|-----------|-------------------|
| Hetzner | CPX31 | $17 | Hasta 32B parÃ¡metros |
| DigitalOcean | Basic 8GB | $48 | Hasta 32B parÃ¡metros |
| Vultr | 16GB | $48 | Hasta 70B parÃ¡metros |
| AWS EC2 | t3.xlarge | $70-100 | Hasta 70B parÃ¡metros |

### ComparaciÃ³n con APIs comerciales

**Tu servidor Ollama (Hetzner CPX31)**:
- **Costo fijo**: $17/mes
- **Requests ilimitados**
- **Privacidad total**
- **Sin latencias de API externa**

**OpenAI API**:
- **Costo por uso**: ~$0.01-0.03 por 1000 tokens
- **10,000 requests/mes** = $100-300/mes aprox
- **LÃ­mites de rate**
- **Datos enviados a terceros**

**Ahorro anual**: ~$1,000-3,000 USD

---

## ðŸŽ¯ PrÃ³ximos Pasos

1. âœ… **Servidor configurado** con script automÃ¡tico
2. âœ… **DNS configurado** apuntando a tu servidor
3. âœ… **SSL habilitado** con Let's Encrypt
4. âœ… **Variable de entorno** aÃ±adida en Vercel
5. ðŸš€ **Deploy** de nueva versiÃ³n

### Ahora puedes:

```bash
# En tu proyecto local:
npm run build
vercel --prod --yes

# Tu app en producciÃ³n ahora usarÃ¡ tu servidor Ollama
```

---

## ðŸ“ž Soporte

### Logs Ãºtiles

```bash
# Logs de Ollama
journalctl -u ollama -f

# Logs de Nginx
tail -f /var/log/nginx/error.log
tail -f /var/log/nginx/access.log

# Uso de sistema
htop
df -h
free -h
```

### Comunidad

- **Ollama Discord**: https://discord.gg/ollama
- **Ollama GitHub**: https://github.com/ollama/ollama
- **DocumentaciÃ³n oficial**: https://ollama.com/docs

---

## ðŸŽ‰ ConclusiÃ³n

Ahora tienes:
- âœ… Tu propia IA local funcionando 24/7
- âœ… Sin lÃ­mites de uso
- âœ… Privacidad total (datos no salen de tu servidor)
- âœ… Costo fijo predecible (~$17-50/mes)
- âœ… Integrada con tu app en Vercel

**Â¡Tu ecosistema premium ahora tiene IA propia!** ðŸš€

---

**Ãšltima actualizaciÃ³n**: Octubre 30, 2025
**VersiÃ³n**: 1.0.0
