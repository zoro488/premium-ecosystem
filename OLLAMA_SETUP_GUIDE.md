# ğŸ§  GuÃ­a Completa: Ollama + ZeroForce AI

## ğŸ“‹ Ãndice
1. [InstalaciÃ³n AutomÃ¡tica](#instalaciÃ³n-automÃ¡tica)
2. [InstalaciÃ³n Manual](#instalaciÃ³n-manual)
3. [ConfiguraciÃ³n en ZeroForce](#configuraciÃ³n-en-zeroforce)
4. [Modelos Recomendados](#modelos-recomendados)
5. [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)

---

## ğŸš€ InstalaciÃ³n AutomÃ¡tica

### OpciÃ³n 1: Script Automatizado (Recomendado)

```powershell
# Ejecutar el script de configuraciÃ³n automÃ¡tica
.\SETUP_OLLAMA.ps1
```

Este script harÃ¡ todo por ti:
- âœ… Verificar si Ollama estÃ¡ instalado
- âœ… Descargar e instalar Ollama si es necesario
- âœ… Iniciar el servidor automÃ¡ticamente
- âœ… Descargar el modelo que elijas
- âœ… Configurar todo listo para usar

---

## ğŸ› ï¸ InstalaciÃ³n Manual

### Paso 1: Instalar Ollama

#### Windows
1. Descarga el instalador desde: https://ollama.com/download
2. Ejecuta `OllamaSetup.exe`
3. Sigue el asistente de instalaciÃ³n
4. Reinicia tu terminal

#### Verificar InstalaciÃ³n
```powershell
ollama --version
```

### Paso 2: Iniciar el Servidor

#### OpciÃ³n A - Ventana Visible (Para monitorear)
```powershell
ollama serve
```
âœ… **DÃ‰JALO CORRIENDO** - No cierres esta ventana

#### OpciÃ³n B - En Segundo Plano
```powershell
Start-Process ollama -ArgumentList "serve" -WindowStyle Minimized
```

#### Verificar que estÃ¡ corriendo
Abre tu navegador y ve a: http://localhost:11434

DeberÃ­as ver:
```
Ollama is running
```

### Paso 3: Descargar un Modelo

#### Modelo Recomendado - Mejor para EspaÃ±ol
```powershell
ollama pull qwen2.5:7b
```
- â±ï¸ Tiempo: 5-10 minutos
- ğŸ“¦ TamaÃ±o: ~4.7 GB
- ğŸŒŸ Mejor rendimiento en espaÃ±ol
- ğŸ’ª Requiere ~8 GB RAM

#### Modelo RÃ¡pido - Si tienes poca RAM
```powershell
ollama pull llama3.2
```
- â±ï¸ Tiempo: 3-5 minutos
- ğŸ“¦ TamaÃ±o: ~2 GB
- âš¡ Respuestas rÃ¡pidas
- ğŸ’» Funciona con ~4 GB RAM

#### Otros Modelos Ãštiles

**Para EspaÃ±ol Avanzado:**
```powershell
ollama pull mistral
```
- ğŸ“¦ ~4.1 GB
- ğŸ‡ªğŸ‡¸ Excelente con espaÃ±ol
- âš–ï¸ Equilibrado velocidad/calidad

**Para CÃ³digo:**
```powershell
ollama pull codellama
```
- ğŸ“¦ ~3.8 GB
- ğŸ’» Especializado en programaciÃ³n
- ğŸ”§ Ideal para desarrollo

**Modelos PequeÃ±os (Para computadoras limitadas):**
```powershell
ollama pull phi
```
- ğŸ“¦ ~1.6 GB
- âš¡ Muy rÃ¡pido
- ğŸ’» MÃ­nimo uso de RAM

### Paso 4: Verificar Modelos Instalados

```powershell
ollama list
```

Salida esperada:
```
NAME              ID              SIZE      MODIFIED
qwen2.5:7b        a1b2c3d4e5f6   4.7 GB    2 minutes ago
```

---

## âš™ï¸ ConfiguraciÃ³n en ZeroForce

### 1ï¸âƒ£ Iniciar tu AplicaciÃ³n

```powershell
npm run dev
```

### 2ï¸âƒ£ Abrir en el Navegador

Navega a: **http://localhost:3001**

### 3ï¸âƒ£ Abrir ZeroForce

Busca el **botÃ³n flotante ğŸ§ ** en la esquina **inferior derecha** de la pantalla.

### 4ï¸âƒ£ Acceder a ConfiguraciÃ³n

Haz clic en el icono **âš™ï¸ Settings** en la parte superior del panel de ZeroForce.

### 5ï¸âƒ£ Configurar Ollama

Completa los siguientes campos:

| Campo | Valor |
|-------|-------|
| **Ollama Host** | `http://localhost:11434` |
| **Modelo** | Selecciona el que descargaste (ej: `qwen2.5:7b`) |
| **Streaming** | âœ… Activado (recomendado) |
| **Temperatura** | `0.7` (creatividad moderada) |
| **Max Tokens** | `2048` (respuestas completas) |

### 6ï¸âƒ£ Opciones Adicionales (Opcional)

- **ğŸ”Š Texto a Voz**: Activa si quieres que ZeroForce hable
- **ğŸ¤ Voz a Texto**: Activa para dictar mensajes
- **ğŸ¨ Tema**: Elige entre claro/oscuro
- **ğŸ’¾ Historial**: Guardar conversaciones

### 7ï¸âƒ£ Guardar ConfiguraciÃ³n

Haz clic en **ğŸ’¾ Guardar** en la parte inferior.

### 8ï¸âƒ£ Â¡Empieza a Chatear!

Escribe tu primer mensaje en el campo de texto y presiona Enter.

**Ejemplos de consultas:**
```
- "ExplÃ­came cÃ³mo funciona React"
- "AyÃºdame a optimizar este cÃ³digo"
- "Â¿CuÃ¡les son las mejores prÃ¡cticas de Firebase?"
```

---

## ğŸ“Š Modelos Recomendados

### Comparativa de Modelos

| Modelo | TamaÃ±o | RAM MÃ­nima | Velocidad | EspaÃ±ol | CÃ³digo | Uso |
|--------|--------|------------|-----------|---------|--------|-----|
| **qwen2.5:7b** | 4.7 GB | 8 GB | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | **Recomendado para espaÃ±ol** |
| **llama3.2** | 2 GB | 4 GB | â­â­â­â­â­ | â­â­â­ | â­â­â­ | **RÃ¡pido y ligero** |
| **mistral** | 4.1 GB | 8 GB | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | Equilibrado |
| **codellama** | 3.8 GB | 8 GB | â­â­â­ | â­â­ | â­â­â­â­â­ | **Especializado en cÃ³digo** |
| **phi** | 1.6 GB | 2 GB | â­â­â­â­â­ | â­â­ | â­â­ | Ultra ligero |

### Recomendaciones por Caso de Uso

#### ğŸ‡ªğŸ‡¸ Para EspaÃ±ol General
```powershell
ollama pull qwen2.5:7b
```

#### ğŸ’» Para ProgramaciÃ³n
```powershell
ollama pull codellama
```

#### âš¡ Para Velocidad
```powershell
ollama pull llama3.2
```

#### ğŸ–¥ï¸ Para Computadoras Limitadas
```powershell
ollama pull phi
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### âŒ Error: "Ollama is not running"

**SoluciÃ³n:**
```powershell
# Verificar si estÃ¡ corriendo
curl http://localhost:11434

# Si no responde, iniciar el servidor
ollama serve
```

### âŒ Error: "Model not found"

**SoluciÃ³n:**
```powershell
# Ver modelos instalados
ollama list

# Descargar el modelo que falta
ollama pull qwen2.5:7b
```

### âŒ Error: "Connection refused"

**Causa:** El servidor Ollama no estÃ¡ iniciado.

**SoluciÃ³n:**
```powershell
# Iniciar el servidor
Start-Process ollama -ArgumentList "serve" -WindowStyle Minimized

# Esperar 5 segundos
Start-Sleep -Seconds 5

# Verificar
curl http://localhost:11434
```

### âŒ Respuestas Muy Lentas

**Causas posibles:**
1. Modelo muy grande para tu RAM
2. CPU/GPU sobrecargada

**Soluciones:**
```powershell
# OpciÃ³n 1: Cambiar a un modelo mÃ¡s pequeÃ±o
ollama pull llama3.2

# OpciÃ³n 2: Cerrar aplicaciones innecesarias

# OpciÃ³n 3: Ajustar parÃ¡metros en ZeroForce:
# - Reducir "Max Tokens" a 1024
# - Reducir "Temperatura" a 0.5
```

### âŒ Error: "Out of Memory"

**SoluciÃ³n:**
```powershell
# Usar un modelo mÃ¡s pequeÃ±o
ollama pull phi

# O liberar memoria RAM
# Cerrar aplicaciones pesadas
```

### âŒ Puerto 11434 Ya EstÃ¡ en Uso

**SoluciÃ³n:**
```powershell
# Ver quÃ© proceso estÃ¡ usando el puerto
netstat -ano | findstr :11434

# Detener el proceso (reemplaza <PID> con el nÃºmero real)
taskkill /PID <PID> /F

# Reiniciar Ollama
ollama serve
```

### âŒ ZeroForce No Encuentra Ollama

**VerificaciÃ³n:**
1. âœ… Â¿Ollama estÃ¡ instalado? â†’ `ollama --version`
2. âœ… Â¿El servidor estÃ¡ corriendo? â†’ `curl http://localhost:11434`
3. âœ… Â¿Hay modelos descargados? â†’ `ollama list`
4. âœ… Â¿La URL en ZeroForce es correcta? â†’ `http://localhost:11434`

---

## ğŸ“š Comandos Ãštiles

### GestiÃ³n de Modelos

```powershell
# Listar modelos instalados
ollama list

# Descargar un modelo
ollama pull <nombre-modelo>

# Eliminar un modelo
ollama rm <nombre-modelo>

# InformaciÃ³n de un modelo
ollama show <nombre-modelo>
```

### Servidor

```powershell
# Iniciar servidor (ventana visible)
ollama serve

# Iniciar en segundo plano
Start-Process ollama -ArgumentList "serve" -WindowStyle Hidden

# Verificar estado
curl http://localhost:11434

# Detener servidor (Windows)
Get-Process ollama | Stop-Process
```

### Testing

```powershell
# Probar un modelo directamente
ollama run qwen2.5:7b

# Chat interactivo
ollama run qwen2.5:7b "Hola, Â¿cÃ³mo estÃ¡s?"

# Salir del chat
/bye
```

---

## ğŸ¯ Mejores PrÃ¡cticas

### âœ… DO's

1. **MantÃ©n el servidor corriendo** mientras uses ZeroForce
2. **Usa streaming** para respuestas mÃ¡s fluidas
3. **Selecciona el modelo apropiado** segÃºn tu hardware
4. **Actualiza Ollama** regularmente: `ollama update`
5. **Monitorea el uso de RAM** con el Administrador de Tareas

### âŒ DON'Ts

1. **No descargues todos los modelos** - Ocupan mucho espacio
2. **No uses modelos grandes** si tienes poca RAM
3. **No cierres el servidor** si estÃ¡s usando ZeroForce
4. **No ignores los errores** - Siempre verifica los logs

---

## ğŸ”— Enlaces Ãštiles

- **Ollama Oficial**: https://ollama.com
- **DocumentaciÃ³n**: https://github.com/ollama/ollama
- **Modelos Disponibles**: https://ollama.com/library
- **Discord Ollama**: https://discord.gg/ollama
- **Repositorio ZeroForce**: (Tu repo)

---

## ğŸ“ Soporte

Â¿Problemas? Contacta:
- ğŸ’¬ Discord: [Tu servidor]
- ğŸ“§ Email: [Tu email]
- ğŸ› Issues: [GitHub Issues]

---

## ğŸ‰ Â¡Todo Listo!

Si has llegado hasta aquÃ­, Â¡felicidades! Ya tienes Ollama configurado con ZeroForce.

**PrÃ³ximos pasos:**
1. Experimenta con diferentes modelos
2. Ajusta los parÃ¡metros segÃºn tus necesidades
3. Integra ZeroForce en tu flujo de trabajo
4. Â¡Disfruta de tu asistente AI local!

---

*Ãšltima actualizaciÃ³n: Octubre 2025*
*VersiÃ³n: 1.0.0*
